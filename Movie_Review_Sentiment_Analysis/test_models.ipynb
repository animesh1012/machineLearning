{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3c44ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "437b582d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 19:07:24.439576: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2025-07-03 19:07:24.439599: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-07-03 19:07:24.439605: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-07-03 19:07:24.439911: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-07-03 19:07:24.440488: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-07-03 19:07:25.415943: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model_1 = tf.keras.models.load_model(\"./Sentiment_Classifier_v1\")\n",
    "model_3 = tf.keras.models.load_model(\"./Sentiment_Classifier_v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9163b5c8",
   "metadata": {},
   "source": [
    "### Sentiment Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fcce217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk, string\n",
    "\n",
    "punctuation = string.punctuation\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "lm = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    text = \"\".join([char.lower() for char in text if char not in punctuation])\n",
    "    tokens = word_tokenize(text)\n",
    "    text = \" \".join([lm.lemmatize(char) for char in tokens if char not in stopwords])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3c32c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/animesh/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4b422fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'left edge seat throughout'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(\"I was left on the edge of my seat throughout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98b9a259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "\n",
      "Query: I was left on the edge of my seat throughout\n",
      "Model 1:\n",
      "Positive Sentiment \n",
      "Score: 0.99069947\n",
      "\n",
      "Model 2:\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "Positive Sentiment \n",
      "Score: 0.9386788\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "\n",
      "Query: The cinematographer’s lensing captured visceral emotion\n",
      "Model 1:\n",
      "Positive Sentiment \n",
      "Score: 0.95213175\n",
      "\n",
      "Model 2:\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Positive Sentiment \n",
      "Score: 0.9944478\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "\n",
      "Query: I hated the first half, yet the ending made it worth watching.\n",
      "Model 1:\n",
      "Negative Sentiment \n",
      "Score: 0.0012903499\n",
      "\n",
      "Model 2:\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Positive Sentiment \n",
      "Score: 0.6605513\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "\n",
      "Query: Well, that was a disaster wrapped in fancy cinematography\n",
      "Model 1:\n",
      "Positive Sentiment \n",
      "Score: 0.99102986\n",
      "\n",
      "Model 2:\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Negative Sentiment \n",
      "Score: 0.42769992\n"
     ]
    }
   ],
   "source": [
    "Test_text = [\n",
    "    'I was left on the edge of my seat throughout',\n",
    "    'The cinematographer’s lensing captured visceral emotion',\n",
    "    'I hated the first half, yet the ending made it worth watching.',\n",
    "    ##Sarcasm\n",
    "    'Well, that was a disaster wrapped in fancy cinematography',\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "for query in Test_text:\n",
    "    \n",
    "    \n",
    "    ##Model 1 Prediction\n",
    "    prediction = model_1.predict(np.array([clean_text(query)]))\n",
    "    print(\"\\nQuery:\", query)\n",
    "    print(\"Model 1:\")\n",
    "    if(prediction[0]>0.5):\n",
    "        print(\"Positive Sentiment\", \"\\nScore:\",prediction[0][0])\n",
    "    else:\n",
    "        print(\"Negative Sentiment\",\"\\nScore:\",prediction[0][0])\n",
    "    \n",
    "    ##Model 2 Prediction\n",
    "    print(\"\\nModel 2:\")\n",
    "    prediction = model_3.predict(np.array([clean_text(query)]))\n",
    "    if(prediction[0]>0.5):\n",
    "        print(\"Positive Sentiment\", \"\\nScore:\",prediction[0][0])\n",
    "    else:\n",
    "        print(\"Negative Sentiment\",\"\\nScore:\",prediction[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3325858d",
   "metadata": {},
   "source": [
    "#### Embedding initialization\n",
    "\n",
    "- Part 1’s Embedding(vocab_size, 100) layer is randomly initialized and must learn word vectors from scratch.\n",
    "\n",
    "- Part 3 trains a Word2Vec (CBOW) model on your cleaned, tokenized corpus (vector size = 200), builds an embedding_matrix from those vectors, and then do\n",
    "- Benefit: Starting from Word2Vec gives you semantically rich vectors (e.g. “good” is close to “great”), so the LSTM can focus on learning classification patterns rather than also discovering basic word semantics.\n",
    "\n",
    "#### Embedding dimension\n",
    "- Part 1 uses 100-dim embeddings.\n",
    "- Part 3 uses 200-dim vectors from Word2Vec.\n",
    "- Benefit: Higher-dimensional embeddings can encode more nuanced meaning (at the cost of a few more parameters), which often helps classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b9244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2561f45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
